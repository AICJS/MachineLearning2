install.packages("GGally")
install.packages("skimr")
install.packages("tidyverse")
install.packages("tidymodels")
install.packages("caret")
install.packages("car")
install.packages("broom")
install.packages("dplyr")
install.packages("pROC")
install.packages("e1071")

library(GGally)
library(skimr)
library(tidyverse)
library(tidymodels)
library(caret)
library(car)
library(broom)
library(dplyr)
library(pROC)
library(e1071)



df <- read.csv("C:/Users/PC502/Desktop/UniversalBank.csv", header = TRUE, na = ".")
skim(df)

df$Personal.Loan <- ifelse(df$Personal.Loan == 1, "yes", "no")
df$Personal.Loan <- as.factor(df$Personal.Loan)

trainIndex <- createDataPartition(df$Personal.Loan, p = 0.8, list = FALSE)
train_data <- df_test[trainIndex]
test_data <- df_test[-trainIndex]



result = glm(tain_data$Personal.Loan ~., data = train_data, family = "binomial")

tidy_result <- tidy(result)
tidy_result <- mutate_if(tidy_result, is.numeric, round, 3)

print(tidy_result)



# 다중공선성(변수의 중복성) : 8 이상 GVIF^(1/(2*DF))
vif(result)

# 다중공선성 위배 변수 제거 후 다시 분석
result = glm(train_data$ ~., data = train_data, family = "binomial")

# Cook's distance 계산 (glm에도 사용 가능)
influencePlot(result, id.method = "identify")



# 기준 설정
# 상위 몇 %를 영향점으로 봄
cooks_d cooks.distance(result)
n <- nrow(train_data)

# Cooks'D 값을 cutoff보다 큰 관측치만 추출
cutoff <- 4 / n
influential_idx <- which(cooks_d > cutoff)

influential_idx



# Test 데이터셋 결과
test_predictions <- predict(result, newdata = test_data, type = "response")
predicted_class <- ifelse(test_predictions > 0.5, "yes", "no")
predicted_class <- as.factor(predicted_class)
print(predicted_class)

# 모델 저장
saveRDS(result, file = "logistic_model.rds")

# 모델 로드
Load <- readRDS("logistic_model.rds")

tidy_result <- tidy(Load)
tidy_result
tidy_result <- mutate_if(tidy_result, is.numeric, round, 3)



# 모델의 Confusion matrix
confusion_matrix <- confusionMatrix(predicted_class, test_data$Personal.Loan)
confusion_matrix

# Mcnemar's Test P-Value(혼동행렬에서 오류가 비대칭인지 파악 : 0.05보다 크면 데이터가 대칭적)
# Kappa(데이터가 한쪽이 너무 많을 때, 한쪽의 값을 도출해도 정확도가 높기 때문에 우연으로 맞췄는지 실제로 맞췄는지를 평가함)
# Kappa값이 1에 가까울 수록 좋은 모델, -값을 가지면 무작위로 예측하는 것 보다 정확도가 낮다는 의미(과적합 판단)

# ROC curve and AUC
roc_curve <- roc(test_data$Personal.Loan, test_predictions)
plot(roc_curve)
auc(roc_curve)

# 새로운 데이터를 활용한 모델 적용
df_test <- read.csv("C:/Users/PC502/Desktop/UniversalBank_test.csv", header = TRUE)
